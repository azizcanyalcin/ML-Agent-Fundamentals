# ğŸ¤– ML-Agent-Fundamentals
A beginner-friendly guide to Unity ML-Agents reinforcement learning

## ğŸ¯ Overview
This project demonstrates how to create and train an intelligent agent using Unity ML-Agents. Watch as your agent learns to navigate and find goals through reinforcement learning! Perfect for developers getting started with ML-Agents.

## âœ¨ Features
- ğŸ® Simple environment setup for ML-Agents
- ğŸ§  Basic reinforcement learning implementation
- ğŸ¯ Goal-seeking behavior training
- ğŸ“Š Training configuration examples
- ğŸ”„ Easy-to-understand training loop

## ğŸ› ï¸ Prerequisites
- Unity 2020.3 or later
- Python 3.6 or later
- ML-Agents Release 2.0 or later

## ğŸ“¦ Installation

1. **Clone the Repository**
```bash
git clone https://github.com/yourusername/ML-Agent-Fundamentals.git
cd ML-Agent-Fundamentals
```

2. **Install Python Dependencies**
```bash
pip install mlagents
pip install torch
```

3. **Unity Setup**
- Open Unity Hub
- Add project from disk
- Install required Unity version if prompted
- Open project

## ğŸš€ Getting Started

1. **Open the Demo Scene**
- Navigate to `Assets/Scenes`
- Open `TrainingScene`

2. **Configure the Environment**
```yaml
behaviors:
  GoalSeeker:
    trainer_type: ppo
    hyperparameters:
      batch_size: 64
      buffer_size: 12000
      learning_rate: 0.0003
    network_settings:
      normalize: true
      hidden_units: 128
      num_layers: 2
    reward_signals:
      extrinsic:
        strength: 1.0
```

3. **Start Training**
```bash
mlagents-learn config/trainer_config.yaml --run-id=first_training
```

## ğŸ® Project Structure
```
ML-Agent-Fundamentals/
â”œâ”€â”€ Assets/
â”‚   â”œâ”€â”€ Scripts/
â”‚   â”‚   â”œâ”€â”€ GoalSeekerAgent.cs
â”‚   â”‚   â””â”€â”€ EnvironmentController.cs
â”‚   â”œâ”€â”€ Scenes/
â”‚   â”‚   â””â”€â”€ TrainingScene
â”‚   â””â”€â”€ Prefabs/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ trainer_config.yaml
â””â”€â”€ README.md
```

## ğŸ“ Key Components

### GoalSeekerAgent Script
The main agent script that handles:
- ğŸ‘ï¸ Observations
- ğŸ¯ Actions
- ğŸ† Rewards
- ğŸ”„ Environment reset

```csharp
public class GoalSeekerAgent : Agent
{
    public override void CollectObservations(VectorSensor sensor)
    {
        // Add observations here
    }

    public override void OnActionReceived(ActionBuffers actions)
    {
        // Handle actions and rewards here
    }
}
```

## ğŸ“Š Training Process

1. **Environment Setup**
   - Create training area
   - Place agent and goals
   - Configure observations and rewards

2. **Training Configuration**
   - Adjust hyperparameters
   - Set network architecture
   - Define reward signals

3. **Training Loop**
   - Run training sessions
   - Monitor progress
   - Adjust parameters as needed

## ğŸ“ˆ Results
Track your agent's progress through:
- ğŸ“Š TensorBoard metrics
- ğŸ® Unity Editor visualization
- ğŸ“ Training logs

## ğŸ¤ Contributing
We welcome contributions! Please feel free to:
1. Fork the project
2. Create your feature branch
3. Submit a pull request

## ğŸ“œ License
This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™‹â€â™‚ï¸ Support
If you have any questions or run into issues:
1. Check the [Issues](https://github.com/yourusername/ML-Agent-Fundamentals/issues) page
2. Create a new issue if needed
3. Join our Discord community [optional]

## â­ Acknowledgments
- Unity ML-Agents team
- Unity Technologies
- The amazing reinforcement learning community

## ğŸ”— Useful Links
- [ML-Agents Documentation](https://github.com/Unity-Technologies/ml-agents)
- [Unity Learn](https://learn.unity.com/)
- [ML-Agents Forum](https://forum.unity.com/forums/ml-agents.453/)
